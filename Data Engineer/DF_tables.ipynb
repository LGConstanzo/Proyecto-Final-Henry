{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CREACIÓN DE LOS DATAFRAME**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Teams, Teams_History, Location y Arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los CSV a los dfs con las columnas que vamos a ocupar\n",
    "df_team = pd.read_csv('csv/team.csv', usecols=['id', 'full_name','abbreviation','city', 'state'])\n",
    "df_team_details = pd.read_csv('csv/team_details.csv', usecols=['team_id','owner', 'generalmanager','headcoach', 'arena', 'arenacapacity'])\n",
    "df_team_history = pd.read_csv('csv/team_history.csv', usecols=['team_id', 'year_founded', 'year_active_till'])\n",
    "\n",
    "# Renombrar la columna id a team_id\n",
    "df_team = df_team.rename(columns={'id': 'team_id'})\n",
    "\n",
    "# Fusionar las tablas df_team y df_team_details\n",
    "df_fusionado = pd.merge(df_team, df_team_details, on='team_id', how='outer')\n",
    "\n",
    "# Fusionar la tabla resultante anterior con df_team_history\n",
    "df_fusionado2 = pd.merge(df_fusionado, df_team_history, on='team_id', how='outer')\n",
    "\n",
    "teams = df_fusionado2.rename(columns={'team_id': 'id'})\n",
    "\n",
    "# Encontrar el valor máximo de la columna 'year_active_till'\n",
    "max_year_active_till = teams['year_active_till'].max()\n",
    "\n",
    "# Agregar la columna 'estado' basada en la condición\n",
    "teams['estado'] = np.where(teams['year_active_till'] < max_year_active_till, 0, 1)\n",
    "\n",
    "# Agregado de la tabla location al dataframe\n",
    "# Crear un nuevo DataFrame con las columnas \"state\" y \"city\"\n",
    "location = pd.DataFrame(teams, columns=['state','city'])\n",
    "\n",
    "# Eliminar filas duplicadas basadas en la columna \"city\"\n",
    "df_location_sin_duplicados = location.drop_duplicates(subset=['city'])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas\n",
    "location = df_location_sin_duplicados\n",
    "\n",
    "# Generar una columna \"ID\" con valores únicos\n",
    "location['ID_location'] = range(1, len(location) + 1) \n",
    "\n",
    "# Unir los DataFrames en función de las columnas \"city\" y \"state\"\n",
    "merge_location = pd.merge(teams, location, on=['city','state'], how='left')\n",
    "\n",
    "teams = merge_location\n",
    "\n",
    "teams = teams.drop(columns=['city','state'])\n",
    "\n",
    "##Agregado de la tabla arena al dataframe\n",
    "# Crear un nuevo DataFrame con las columnas \"arena\" y \"arenacapacity\"\n",
    "arena = pd.DataFrame(teams, columns=['arena','arenacapacity'])\n",
    "\n",
    "# Eliminar filas duplicadas basadas en la columna \"city\"\n",
    "df_arena_sin_duplicados = arena.drop_duplicates(subset=['arena'])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas\n",
    "arena = df_arena_sin_duplicados\n",
    "\n",
    "# Generar una columna \"ID\" con valores únicos\n",
    "arena['ID_arena'] = range(1, len(arena) + 1) \n",
    "\n",
    "# Unir los DataFrames en función de las columnas \"city\" y \"state\"\n",
    "merge_arena = pd.merge(teams, arena, on=['arenacapacity','arena'], how='left')\n",
    "\n",
    "teams = merge_arena\n",
    "\n",
    "teams.rename(columns={\"id\": \"ID_team\"}, inplace=True)\n",
    "\n",
    "teams = teams.drop(columns=['arenacapacity','arena','year_founded','year_active_till','estado'])\n",
    "\n",
    "teams_History = df_team_history.rename(columns={'team_id': 'ID_team'})\n",
    "\n",
    "# Generar una columna \"ID\" con valores únicos\n",
    "teams_History['ID_history'] = range(1, len(teams_History) + 1)\n",
    "\n",
    "teams = teams.drop_duplicates(subset='ID_team')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe de City y State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df city\n",
    "city_unique = df_team['city'].unique()  # Obtiene los valores únicos de la columna 'city'\n",
    "city = pd.DataFrame(city_unique, columns=['city'])  # Crea un DataFrame con los valores únicos\n",
    "\n",
    "city['ID_city'] = range(1, len(city) + 1)  #Creo el indice\n",
    "\n",
    "# Df state\n",
    "state_unique = df_team['state'].unique()  # Obtiene los valores únicos de la columna 'state'\n",
    "state = pd.DataFrame(state_unique, columns=['state'])  # Crea un DataFrame con los valores únicos\n",
    "\n",
    "state['ID_state'] = range(1, len(state) + 1)  #Creo el indice\n",
    "\n",
    "#Megere\n",
    "# Unir los DataFrames en función de las columnas \"city\" y \"state\"\n",
    "merge_city = pd.merge(city, location, on=['city'], how='left')\n",
    "merge_total = pd.merge(state, merge_city, on=['state'], how='left')\n",
    "\n",
    "merge_total = merge_total.drop(columns=['state','city'])\n",
    "\n",
    "#Borro columnas de location\n",
    "location = merge_total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Draft y Proveniencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los archivos CSV\n",
    "df_draft_combine_stats = pd.read_csv('csv/draft_combine_stats.csv')\n",
    "df_draft_history = pd.read_csv('csv/draft_history.csv')\n",
    "\n",
    "# Seleccion de las columnas a utilizar\n",
    "columnas_draft_combine_stats  = ['player_id','weight','wingspan','standing_reach','body_fat_pct','standing_vertical_leap','max_vertical_leap','lane_agility_time','modified_lane_agility_time','three_quarter_sprint','bench_press']\n",
    "df_draft_combine_stats_reducido = df_draft_combine_stats.loc[:,columnas_draft_combine_stats]\n",
    "\n",
    "columnas_draft_history  = ['person_id','season','round_number','round_pick','overall_pick','team_id','organization','organization_type']\n",
    "df_draft_history_reducido = df_draft_history.loc[:,columnas_draft_history]\n",
    "\n",
    "df_draft_history_reducido.rename(columns={\"person_id\": \"player_id\"}, inplace=True)\n",
    "\n",
    "# DataFrame Draft\n",
    "draft = pd.merge(df_draft_combine_stats_reducido, df_draft_history_reducido, on='player_id', how='outer')\n",
    "\n",
    "# Df proveniencia\n",
    "# Crear un nuevo DataFrame con las columnas \"organization\" y \"organization_type\"\n",
    "proveniencia = pd.DataFrame(draft, columns=['organization','organization_type'])  \n",
    "\n",
    "# Eliminar filas duplicadas basadas en la columna \"organization\"\n",
    "df_sin_duplicados = proveniencia.drop_duplicates(subset=[\"organization\"])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas \n",
    "proveniencia = df_sin_duplicados\n",
    "\n",
    "# Generar una columna \"ID\" con valores únicos\n",
    "proveniencia[\"ID_proveniencia\"] = range(1, len(proveniencia) + 1)\n",
    "\n",
    "# Unir los DataFrames en función de las columnas \"organization\" y \"organization_type\"\n",
    "merge = pd.merge(draft, proveniencia, on=[\"organization\", \"organization_type\"], how=\"left\")\n",
    "\n",
    "draft = merge\n",
    "\n",
    "draft = draft.drop(columns=['organization','organization_type'])\n",
    "\n",
    "draft = draft.rename(columns={'player_id':'ID_player', 'team_id':'ID_team'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV\n",
    "df_common_player_info = pd.read_csv('csv/common_player_info.csv')\n",
    "df_inactive_players = pd.read_csv('csv/inactive_players.csv')\n",
    "df_player = pd.read_csv('csv/player.csv')\n",
    "\n",
    "#DF Players\n",
    "player = df_common_player_info.drop(columns=['display_first_last','school','country','display_last_comma_first','display_fi_last','player_slug','last_affiliation','rosterstatus','games_played_current_season_flag','team_name','team_abbreviation','team_code','team_city','playercode','from_year','to_year','dleague_flag','nba_flag','games_played_flag','draft_year','draft_round','draft_number','greatest_75_flag'])\n",
    "# Renombrar la columna id a person_id\n",
    "df_player = df_player.rename(columns={'id': 'person_id'})\n",
    "\n",
    "# Fusionar las tablas df_player y player\n",
    "player = pd.merge(player, df_player, on='person_id', how='inner')\n",
    "player = player.drop(columns=['last_name_y','first_name_y','full_name'])\n",
    "\n",
    "# Renombrar la columna id a ID_player\n",
    "player = player.rename(columns={'person_id': 'ID_player', 'first_name_x':'first_name', 'last_name_x':'last_name', 'team_id':'ID_team'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Games, Game Stats y Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_20864\\2576522411.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  game_stats['ID_game_stats'] = range(1, len(game_stats) + 1)  # Creación del id\n"
     ]
    }
   ],
   "source": [
    "# Cargar los archivos CSV\n",
    "df_game = pd.read_csv('csv/game.csv')  \n",
    "df_game_info = pd.read_csv('csv/game_info.csv')  \n",
    "df_game_summary = pd.read_csv('csv/game_summary.csv')  \n",
    "df_line_score = pd.read_csv('csv/line_score.csv')\n",
    "\n",
    "# Unir las tablas\n",
    "df_combine = df_game.merge(df_game_info, on='game_id', how='inner')\n",
    "\n",
    "df_combine_summary = df_combine.merge(df_game_summary, on='game_id', how='inner')\n",
    "\n",
    "df_combine_total = df_combine_summary.merge(df_line_score, on='game_id', how='inner')\n",
    "\n",
    "# Seleccionar las columnas\n",
    "\n",
    "game_stats = df_combine_total[['game_id','pts_home_x', 'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home', 'pts_qtr4_home', \n",
    "                                  'pts_qtr1_away', 'pts_qtr2_away', 'pts_qtr3_away', 'pts_qtr4_away', 'pts_away_x', \n",
    "                                 'attendance', 'game_time', 'natl_tv_broadcaster_abbreviation', 'live_period_time_bcast']]\n",
    "\n",
    "game_stats['ID_game_stats'] = range(1, len(game_stats) + 1)  # Creación del id\n",
    "\n",
    "\n",
    "df_games = df_combine_total[['game_id', 'game_date_x', 'team_id_home_x', 'wl_home', 'team_id_away_x', 'wl_away', 'season_id', 'season', 'season_type']]\n",
    "\n",
    "# Renombrar la columna team_id_home a ID_team en df_games\n",
    "df_games = df_games.rename(columns={'team_id_home_x': 'ID_team'})\n",
    "\n",
    "games = pd.merge(df_games, teams[['ID_team', 'ID_location']], on='ID_team', how='outer')\n",
    "\n",
    "\n",
    "# Renombrar la columna game_id a ID_game\n",
    "games = games.rename(columns={'game_id': 'ID_game', 'game_date_x': 'game_date', 'team_id_away_x': 'team_id_away'})\n",
    "\n",
    "\n",
    "# Creación de tabla de Season \n",
    "df_season = df_combine_total[['season_id', 'season', 'season_type']]\n",
    "season = df_season.drop_duplicates(subset=['season_id'])\n",
    "season = season.rename(columns={'season_id': 'ID_season'})\n",
    "season = season.drop_duplicates(subset='ID_season')\n",
    "\n",
    "games = games.rename(columns={'season_id': 'ID_season'})\n",
    "games = games.drop(columns=['season','season_type'])\n",
    "games = games.drop_duplicates(subset='ID_game')\n",
    "\n",
    "game_stats = game_stats.rename(columns={'game_id': 'ID_game'})\n",
    "\n",
    "# ID_season en tabla de Draft\n",
    "draft = pd.merge(draft, season[['ID_season', 'season']], on='season', how='inner')\n",
    "draft_d = draft.drop(columns=['season'])\n",
    "draft = draft_d\n",
    "\n",
    "draft['ID_draft'] = range(1, len(draft) + 1)  # Creación del id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de los datos a SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "PendingRollbackError",
     "evalue": "Can't reconnect until invalid transaction is rolled back.  Please rollback() fully before proceeding (Background on this error at: https://sqlalche.me/e/20/8s2b)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPendingRollbackError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m games\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGames\u001b[39m\u001b[38;5;124m'\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Estos dan error porque falta corregir el tipo de dato que hay en las tablas o en el dataframe\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mgame_stats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGame_stats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m draft\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDraft\u001b[39m\u001b[38;5;124m'\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m player\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlayer\u001b[39m\u001b[38;5;124m'\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2891\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:841\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, DataFrame):\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m     )\n\u001b[1;32m--> 841\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_transaction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpandas_sql\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:1645\u001b[0m, in \u001b[0;36mSQLDatabase.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1644\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturns_generator:\n\u001b[1;32m-> 1645\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\contextlib.py:618\u001b[0m, in \u001b[0;36mExitStack.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Immediately unwind the context stack.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\contextlib.py:610\u001b[0m, in \u001b[0;36mExitStack.__exit__\u001b[1;34m(self, *exc_details)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;66;03m# bare \"raise exc_details[1]\" replaces our carefully\u001b[39;00m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;66;03m# set-up context\u001b[39;00m\n\u001b[0;32m    609\u001b[0m     fixed_ctx \u001b[38;5;241m=\u001b[39m exc_details[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m__context__\n\u001b[1;32m--> 610\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_details[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m    612\u001b[0m     exc_details[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;241m=\u001b[39m fixed_ctx\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\contextlib.py:595\u001b[0m, in \u001b[0;36mExitStack.__exit__\u001b[1;34m(self, *exc_details)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_sync\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexc_details\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    596\u001b[0m         suppressed_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    597\u001b[0m         pending_raise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\util.py:147\u001b[0m, in \u001b[0;36mTransactionalContext.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rollback_can_be_called\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\util.py:145\u001b[0m, in \u001b[0;36mTransactionalContext.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction_is_active():\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2629\u001b[0m, in \u001b[0;36mTransaction.commit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2613\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Commit this :class:`.Transaction`.\u001b[39;00m\n\u001b[0;32m   2614\u001b[0m \n\u001b[0;32m   2615\u001b[0m \u001b[38;5;124;03mThe implementation of this may vary based on the type of transaction in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2626\u001b[0m \n\u001b[0;32m   2627\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2629\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_commit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2630\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2631\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_active\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2734\u001b[0m, in \u001b[0;36mRootTransaction._do_commit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2731\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   2733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2734\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_commit_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2735\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2736\u001b[0m     \u001b[38;5;66;03m# whether or not commit succeeds, cancel any\u001b[39;00m\n\u001b[0;32m   2737\u001b[0m     \u001b[38;5;66;03m# nested transactions, make this transaction \"inactive\"\u001b[39;00m\n\u001b[0;32m   2738\u001b[0m     \u001b[38;5;66;03m# and remove it as a reset agent\u001b[39;00m\n\u001b[0;32m   2739\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_nested_transaction:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2705\u001b[0m, in \u001b[0;36mRootTransaction._connection_commit_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_connection_commit_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2705\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_commit_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1146\u001b[0m, in \u001b[0;36mConnection._commit_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_commit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection)\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2356\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2355\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2356\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m   2357\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2358\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1144\u001b[0m, in \u001b[0;36mConnection._commit_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOMMIT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_commit(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m)\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(e, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:585\u001b[0m, in \u001b[0;36mConnection.connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 585\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_revalidate_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (exc\u001b[38;5;241m.\u001b[39mPendingRollbackError, exc\u001b[38;5;241m.\u001b[39mResourceClosedError):\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:677\u001b[0m, in \u001b[0;36mConnection._revalidate_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__can_reconnect \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvalidated:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 677\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invalid_transaction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:667\u001b[0m, in \u001b[0;36mConnection._invalid_transaction\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invalid_transaction\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m--> 667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mPendingRollbackError(\n\u001b[0;32m    668\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reconnect until invalid \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124mtransaction is rolled \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    669\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mback.  Please rollback() fully before proceeding\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msavepoint \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nested_transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    671\u001b[0m         code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8s2b\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    672\u001b[0m     )\n",
      "\u001b[1;31mPendingRollbackError\u001b[0m: Can't reconnect until invalid transaction is rolled back.  Please rollback() fully before proceeding (Background on this error at: https://sqlalche.me/e/20/8s2b)"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Parámetros de la conexión\n",
    "server = 'localhost\\\\SQLEXPRESS'  # Reemplaza con el nombre de tu servidor\n",
    "database = 'DAFT01_Grupo1_nba'  # Reemplaza con el nombre de tu base de datos\n",
    "\n",
    "# Crear la cadena de conexión utilizando la autenticación de Windows\n",
    "connection_string = f'mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes'\n",
    "\n",
    "# Crear el motor de conexión\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Mandar los datos a la tabla ya creada en SQL Server\n",
    "season.to_sql('season', engine, if_exists='append', index=False)\n",
    "state.to_sql('State', engine, if_exists='append', index=False)\n",
    "city.to_sql('City', engine, if_exists='append', index=False)\n",
    "arena.to_sql('Arena', engine, if_exists='append', index=False)\n",
    "location.to_sql('Location', engine, if_exists='append', index=False)\n",
    "proveniencia.to_sql('Proveniencia', engine, if_exists='append', index=False)\n",
    "teams.to_sql('teams', engine, if_exists='append', index=False)\n",
    "teams_History.to_sql('teams_History', engine, if_exists='append', index=False)\n",
    "games.to_sql('Games', engine, if_exists='append', index=False)\n",
    "\n",
    "# Estos dan error porque falta corregir el tipo de dato que hay en las tablas o en el dataframe\n",
    "game_stats.to_sql('Game_stats', engine, if_exists='append', index=False)\n",
    "draft.to_sql('Draft', engine, if_exists='append', index=False)\n",
    "player.to_sql('Player', engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
