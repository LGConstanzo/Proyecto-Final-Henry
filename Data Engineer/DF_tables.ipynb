{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CREACIÓN DE LOS DATAFRAME**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lucas\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lucas\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: SQLAlchemy in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.30)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy) (4.12.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas \n",
    "%pip install numpy \n",
    "%pip install SQLAlchemy \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Teams, Teams_History, Location y Arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los CSV a los dfs con las columnas que vamos a ocupar\n",
    "df_team = pd.read_csv('csv/team.csv', usecols=['id', 'full_name','abbreviation','city', 'state'])\n",
    "df_team_details = pd.read_csv('csv/team_details.csv', usecols=['team_id','owner', 'generalmanager','headcoach', 'arena', 'arenacapacity'])\n",
    "df_team_history = pd.read_csv('csv/team_history.csv', usecols=['team_id', 'year_founded', 'year_active_till'])\n",
    "\n",
    "new_teams_data = {\n",
    "    'team_id': [1610612738, 1610612739, 1610612752, 1610612740, 1610612753],\n",
    "    'owner': ['Wyc Grousbeck, Steve Pagliuca, y otros socios', 'Dan Gilbert', 'James Dolan (Madison Square Garden Sports)', 'Gayle Benson', 'RDV Sports, Inc. (familia DeVos)'],\n",
    "    'generalmanager': ['Brad Stevens', 'Mike Gansey', 'Scott Perry', 'Trajan Langdon', 'Anthony Parker'],\n",
    "    'headcoach': ['Joe Mazzulla', 'J.B. Bickerstaff', 'Tom Thibodeau', 'Willie Green', 'Jamahl Mosley'],\n",
    "    'arena': ['TD Garden', 'Rocket Mortgage FieldHouse', 'Madison Square Garden', 'Smoothie King Center', 'Amway Center'],\n",
    "    'arenacapacity': [19156, 19432, 19812, 16867, 18846]\n",
    "}\n",
    "\n",
    "# Crear DataFrame con nuevos datos\n",
    "df_new_teams = pd.DataFrame(new_teams_data)\n",
    "\n",
    "# Concatenar DataFrames\n",
    "df_team_details = pd.concat([df_team_details, df_new_teams], ignore_index=True)\n",
    "\n",
    "# Renombrar la columna id a team_id\n",
    "df_team = df_team.rename(columns={'id': 'team_id'})\n",
    "\n",
    "# Fusionar las tablas df_team y df_team_details\n",
    "df_fusionado = pd.merge(df_team, df_team_details, on='team_id', how='outer')\n",
    "\n",
    "# Fusionar la tabla resultante anterior con df_team_history\n",
    "df_fusionado2 = pd.merge(df_fusionado, df_team_history, on='team_id', how='outer')\n",
    "\n",
    "teams = df_fusionado2.rename(columns={'team_id': 'id'})\n",
    "\n",
    "# Encontrar el valor máximo de la columna 'year_active_till'\n",
    "max_year_active_till = teams['year_active_till'].max()\n",
    "\n",
    "# Agregar la columna 'estado' basada en la condición\n",
    "teams['estado'] = np.where(teams['year_active_till'] < max_year_active_till, 0, 1)\n",
    "\n",
    "# Agregado de la tabla location al dataframe\n",
    "# Crear un nuevo DataFrame con las columnas \"state\" y \"city\"\n",
    "location = pd.DataFrame(teams, columns=['state','city'])\n",
    "\n",
    "# Eliminar filas duplicadas basadas en la columna \"city\"\n",
    "df_location_sin_duplicados = location.drop_duplicates(subset=['city'])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas\n",
    "location = df_location_sin_duplicados\n",
    "\n",
    "# Generar una columna \"ID\" con valores únicos\n",
    "location['ID_location'] = range(1, len(location) + 1) \n",
    "\n",
    "# Unir los DataFrames en función de las columnas \"city\" y \"state\"\n",
    "merge_location = pd.merge(teams, location, on=['city','state'], how='left')\n",
    "\n",
    "teams = merge_location\n",
    "\n",
    "teams = teams.drop(columns=['city','state'])\n",
    "\n",
    "##Agregado de la tabla arena al dataframe\n",
    "# Crear un nuevo DataFrame con las columnas \"arena\" y \"arenacapacity\"\n",
    "arena = pd.DataFrame(teams, columns=['arena','arenacapacity'])\n",
    "\n",
    "# Eliminar filas duplicadas basadas en la columna \"city\"\n",
    "df_arena_sin_duplicados = arena.drop_duplicates(subset=['arena'])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas\n",
    "arena = df_arena_sin_duplicados\n",
    "\n",
    "# Generar una columna \"ID\" con valores únicos\n",
    "arena['ID_arena'] = range(1, len(arena) + 1) \n",
    "\n",
    "# Unir los DataFrames en función de las columnas \"city\" y \"state\"\n",
    "merge_arena = pd.merge(teams, arena, on=['arenacapacity','arena'], how='left')\n",
    "\n",
    "teams = merge_arena\n",
    "\n",
    "teams.rename(columns={\"id\": \"ID_team\"}, inplace=True)\n",
    "\n",
    "teams = teams.drop(columns=['arenacapacity','arena','year_founded','year_active_till','estado'])\n",
    "\n",
    "teams_History = df_team_history.rename(columns={'team_id': 'ID_team'})\n",
    "\n",
    "# Generar una columna \"ID\" con valores únicos\n",
    "teams_History['ID_history'] = range(1, len(teams_History) + 1)\n",
    "\n",
    "teams = teams.drop_duplicates(subset='ID_team')\n",
    "\n",
    "teams.fillna('Darko Rajaković', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe de City y State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df city\n",
    "city_unique = df_team['city'].unique()  # Obtiene los valores únicos de la columna 'city'\n",
    "city = pd.DataFrame(city_unique, columns=['city'])  # Crea un DataFrame con los valores únicos\n",
    "\n",
    "city['ID_city'] = range(1, len(city) + 1)  #Creo el indice\n",
    "\n",
    "# Df state\n",
    "state_unique = df_team['state'].unique()  # Obtiene los valores únicos de la columna 'state'\n",
    "state = pd.DataFrame(state_unique, columns=['state'])  # Crea un DataFrame con los valores únicos\n",
    "\n",
    "state['ID_state'] = range(1, len(state) + 1)  #Creo el indice\n",
    "\n",
    "#Megere\n",
    "# Unir los DataFrames en función de las columnas \"city\" y \"state\"\n",
    "merge_city = pd.merge(city, location, on=['city'], how='left')\n",
    "merge_total = pd.merge(state, merge_city, on=['state'], how='left')\n",
    "\n",
    "merge_total = merge_total.drop(columns=['state','city'])\n",
    "\n",
    "#Borro columnas de location\n",
    "location = merge_total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Draft y Proveniencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los archivos CSV\n",
    "df_draft_combine_stats = pd.read_csv('csv/draft_combine_stats.csv')\n",
    "df_draft_history = pd.read_csv('csv/draft_history.csv')\n",
    "\n",
    "# Seleccion de las columnas a utilizar\n",
    "columnas_draft_combine_stats  = ['player_id','weight','wingspan','standing_reach','body_fat_pct','standing_vertical_leap','max_vertical_leap','lane_agility_time','modified_lane_agility_time','three_quarter_sprint','bench_press']\n",
    "df_draft_combine_stats_reducido = df_draft_combine_stats.loc[:,columnas_draft_combine_stats]\n",
    "\n",
    "columnas_draft_history  = ['person_id','season','player_name','round_number','round_pick','overall_pick','team_id','organization','organization_type']\n",
    "df_draft_history_reducido = df_draft_history.loc[:,columnas_draft_history]\n",
    "\n",
    "df_draft_history_reducido.rename(columns={\"person_id\": \"player_id\"}, inplace=True)\n",
    "\n",
    "# DataFrame Draft\n",
    "draft = pd.merge(df_draft_combine_stats_reducido, df_draft_history_reducido, on='player_id', how='outer')\n",
    "\n",
    "# Df proveniencia\n",
    "# Crear un nuevo DataFrame con las columnas \"organization\" y \"organization_type\"\n",
    "proveniencia = pd.DataFrame(draft, columns=['organization','organization_type'])  \n",
    "\n",
    "# Eliminar filas duplicadas basadas en la columna \"organization\"\n",
    "df_sin_duplicados = proveniencia.drop_duplicates(subset=[\"organization\"])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas \n",
    "proveniencia = df_sin_duplicados\n",
    "\n",
    "# Generar una columna \"ID\" con valores únicos\n",
    "proveniencia[\"ID_proveniencia\"] = range(1, len(proveniencia) + 1)\n",
    "\n",
    "# Unir los DataFrames en función de las columnas \"organization\" y \"organization_type\"\n",
    "merge = pd.merge(draft, proveniencia, on=[\"organization\", \"organization_type\"], how=\"left\")\n",
    "\n",
    "draft = merge\n",
    "\n",
    "draft = draft.drop(columns=['organization','organization_type'])\n",
    "\n",
    "draft = draft.rename(columns={'player_id':'ID_player', 'team_id':'ID_team'})\n",
    "\n",
    "draft = draft[draft['ID_team']>=1610612737]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV\n",
    "df_common_player_info = pd.read_csv('csv/common_player_info.csv')\n",
    "df_inactive_players = pd.read_csv('csv/inactive_players.csv')\n",
    "df_player = pd.read_csv('csv/player.csv')\n",
    "\n",
    "#DF Players\n",
    "player = df_common_player_info.drop(columns=['display_first_last','school','country','display_last_comma_first','display_fi_last','player_slug','last_affiliation','rosterstatus','games_played_current_season_flag','team_name','team_abbreviation','team_code','team_city','playercode','from_year','to_year','dleague_flag','nba_flag','games_played_flag','draft_year','draft_round','draft_number','greatest_75_flag'])\n",
    "# Renombrar la columna id a person_id\n",
    "df_player = df_player.rename(columns={'id': 'person_id'})\n",
    "\n",
    "# Fusionar las tablas df_player y player\n",
    "player = pd.merge(player, df_player, on='person_id', how='inner')\n",
    "player = player.drop(columns=['last_name_y','first_name_y','full_name'])\n",
    "\n",
    "# Renombrar la columna id a ID_player\n",
    "player = player.rename(columns={'person_id': 'ID_player', 'first_name_x':'first_name', 'last_name_x':'last_name', 'team_id':'ID_team'})\n",
    "\n",
    "player = player[player['ID_team']>=1610612737]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Games, Game Stats y Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_25436\\4177038470.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  game_stats['ID_game_stats'] = range(1, len(game_stats) + 1)  # Creación del id\n"
     ]
    }
   ],
   "source": [
    "# Cargar los archivos CSV\n",
    "df_game = pd.read_csv('csv/game.csv')  \n",
    "df_game_info = pd.read_csv('csv/game_info.csv')  \n",
    "df_game_summary = pd.read_csv('csv/game_summary.csv')  \n",
    "df_line_score = pd.read_csv('csv/line_score.csv')\n",
    "\n",
    "# Unir las tablas\n",
    "df_combine = df_game.merge(df_game_info, on='game_id', how='inner')\n",
    "\n",
    "df_combine_summary = df_combine.merge(df_game_summary, on='game_id', how='inner')\n",
    "\n",
    "df_combine_total = df_combine_summary.merge(df_line_score, on='game_id', how='inner')\n",
    "\n",
    "# Seleccionar las columnas\n",
    "\n",
    "game_stats = df_combine_total[['game_id','pts_home_x', 'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home', 'pts_qtr4_home', \n",
    "                                  'pts_qtr1_away', 'pts_qtr2_away', 'pts_qtr3_away', 'pts_qtr4_away', 'pts_away_x', \n",
    "                                 'attendance', 'game_time', 'natl_tv_broadcaster_abbreviation', 'live_period_time_bcast']]\n",
    "\n",
    "game_stats['ID_game_stats'] = range(1, len(game_stats) + 1)  # Creación del id\n",
    "\n",
    "\n",
    "df_games = df_combine_total[['game_id', 'game_date_x', 'team_id_home_x', 'wl_home', 'team_id_away_x', 'wl_away', 'season_id', 'season', 'season_type']]\n",
    "\n",
    "# Renombrar la columna team_id_home a ID_team en df_games\n",
    "df_games = df_games.rename(columns={'team_id_home_x': 'ID_team'})\n",
    "\n",
    "games = pd.merge(df_games, teams[['ID_team', 'ID_location']], on='ID_team', how='outer')\n",
    "\n",
    "\n",
    "# Renombrar la columna game_id a ID_game\n",
    "games = games.rename(columns={'game_id': 'ID_game', 'game_date_x': 'game_date', 'team_id_away_x': 'team_id_away'})\n",
    "\n",
    "\n",
    "# Creación de tabla de Season \n",
    "df_season = df_combine_total[['season_id', 'season', 'season_type']]\n",
    "season = df_season.drop_duplicates(subset=['season_id'])\n",
    "season = season.rename(columns={'season_id': 'ID_season'})\n",
    "season = season.drop_duplicates(subset='ID_season')\n",
    "\n",
    "games = games.rename(columns={'season_id': 'ID_season'})\n",
    "games = games.drop(columns=['season','season_type'])\n",
    "games = games.drop_duplicates(subset='ID_game')\n",
    "\n",
    "game_stats = game_stats.rename(columns={'game_id': 'ID_game'})\n",
    "\n",
    "# ID_season en tabla de Draft\n",
    "draft = pd.merge(draft, season[['ID_season', 'season']], on='season', how='inner')\n",
    "draft_d = draft.drop(columns=['season'])\n",
    "draft = draft_d\n",
    "\n",
    "draft['ID_draft'] = range(1, len(draft) + 1)  # Creación del id\n",
    "\n",
    "games = games[games['ID_team']>=1610612737]\n",
    "\n",
    "\n",
    "# Arreglo de errores\n",
    "\n",
    "prueba = pd.merge(player,draft[['ID_player','player_name']],on='ID_player',how='outer')\n",
    "prueba = prueba.drop_duplicates('ID_player')\n",
    "prueba_2 = prueba.dropna(subset=['player_name'])\n",
    "player = prueba_2.drop(columns=['first_name','last_name'])\n",
    "\n",
    "game_stats = game_stats.drop_duplicates(subset='ID_game')\n",
    "\n",
    "game_stats = pd.merge(game_stats, games['ID_game'], on='ID_game', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de los datos a SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Parámetros de la conexión\n",
    "server = 'localhost\\\\SQLEXPRESS'  # Reemplaza con el nombre de tu servidor\n",
    "database = 'DAFT01_Grupo1_nba'  # Reemplaza con el nombre de tu base de datos\n",
    "\n",
    "# Crear la cadena de conexión utilizando la autenticación de Windows\n",
    "connection_string = f'mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes'\n",
    "\n",
    "# Crear el motor de conexión\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Mandar los datos a la tabla ya creada en SQL Server\n",
    "season.to_sql('season', engine, if_exists='append', index=False)\n",
    "state.to_sql('State', engine, if_exists='append', index=False)\n",
    "city.to_sql('City', engine, if_exists='append', index=False)\n",
    "arena.to_sql('Arena', engine, if_exists='append', index=False)\n",
    "location.to_sql('Location', engine, if_exists='append', index=False)\n",
    "proveniencia.to_sql('Proveniencia', engine, if_exists='append', index=False)\n",
    "teams.to_sql('teams', engine, if_exists='append', index=False)\n",
    "teams_History.to_sql('teams_History', engine, if_exists='append', index=False)\n",
    "games.to_sql('Games', engine, if_exists='append', index=False)\n",
    "game_stats.to_sql('Game_stats', engine, if_exists='append', index=False)\n",
    "player.to_sql('Player', engine, if_exists='append', index=False)\n",
    "draft.to_sql('Draft', engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
