{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la librería\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los CSV a los dfs con las columnas que vamos a ocupar\n",
    "df_team = pd.read_csv('team.csv', usecols=['id', 'full_name','abbreviation','city', 'state'])\n",
    "df_team_details = pd.read_csv('team_details.csv', usecols=['team_id','owner', 'generalmanager','headcoach', 'arena', 'arenacapacity'])\n",
    "df_team_history = pd.read_csv('team_history.csv', usecols=['team_id', 'year_founded', 'year_active_till'])\n",
    "\n",
    "# Renombrar la columna id a team_id\n",
    "df_team = df_team.rename(columns={'id': 'team_id'})\n",
    "\n",
    "# Fusionar las tablas df_team y df_team_details\n",
    "df_fusionado = pd.merge(df_team, df_team_details, on='team_id', how='outer')\n",
    "\n",
    "# Fusionar la tabla resultante anterior con df_team_history\n",
    "df_fusionado2 = pd.merge(df_fusionado, df_team_history, on='team_id', how='outer')\n",
    "\n",
    "teams = df_fusionado2.rename(columns={'team_id': 'id'})\n",
    "\n",
    "# Agregado de la tabla location al dataframe\n",
    "# Crear un nuevo DataFrame con las columnas \"state\" y \"city\"\n",
    "location = pd.DataFrame(teams, columns=['state','city'])\n",
    "\n",
    "# Eliminar filas duplicadas basadas en la columna \"city\"\n",
    "df_location_sin_duplicados = location.drop_duplicates(subset=['city'])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas\n",
    "location = df_location_sin_duplicados\n",
    "\n",
    "# Generar una columna \"ID\" con valores únicos\n",
    "location['ID_location'] = range(1, len(location) + 1) \n",
    "\n",
    "# Unir los DataFrames en función de las columnas \"city\" y \"state\"\n",
    "merge_location = pd.merge(teams, location, on=['city','state'], how='left')\n",
    "\n",
    "teams = merge_location\n",
    "\n",
    "teams = teams.drop(columns=['city','state'])\n",
    "\n",
    "##Agregado de la tabla arena al dataframe\n",
    "# Crear un nuevo DataFrame con las columnas \"arena\" y \"arenacapacity\"\n",
    "arena = pd.DataFrame(teams, columns=['arena','arenacapacity'])\n",
    "\n",
    "# Eliminar filas duplicadas basadas en la columna \"city\"\n",
    "df_arena_sin_duplicados = arena.drop_duplicates(subset=['arena'])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas\n",
    "arena = df_arena_sin_duplicados\n",
    "\n",
    "# Generar una columna \"ID\" con valores únicos\n",
    "arena['ID_arena'] = range(1, len(arena) + 1) \n",
    "\n",
    "# Unir los DataFrames en función de las columnas \"city\" y \"state\"\n",
    "merge_arena = pd.merge(teams, arena, on=['arenacapacity','arena'], how='left')\n",
    "\n",
    "teams = merge_arena\n",
    "\n",
    "teams = teams.drop(columns=['arenacapacity','arena',])\n",
    "\n",
    "teams.rename(columns={\"id\": \"ID_team\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame Draft y Proveniencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los archivos CSV\n",
    "df_draft_combine_stats = pd.read_csv('draft_combine_stats.csv')\n",
    "df_draft_history = pd.read_csv('draft_history.csv')\n",
    "\n",
    "# Seleccion de las columnas a utilizar\n",
    "columnas_draft_combine_stats  = ['player_id','weight','wingspan','standing_reach','body_fat_pct','standing_vertical_leap','max_vertical_leap','lane_agility_time','modified_lane_agility_time','three_quarter_sprint','bench_press']\n",
    "df_draft_combine_stats_reducido = df_draft_combine_stats.loc[:,columnas_draft_combine_stats]\n",
    "\n",
    "columnas_draft_history  = ['person_id','season','round_number','round_pick','overall_pick','team_id','organization','organization_type']\n",
    "df_draft_history_reducido = df_draft_history.loc[:,columnas_draft_history]\n",
    "\n",
    "df_draft_history_reducido.rename(columns={\"person_id\": \"player_id\"}, inplace=True)\n",
    "\n",
    "# DataFrame Draft\n",
    "draft = pd.merge(df_draft_combine_stats_reducido, df_draft_history_reducido, on='player_id', how='outer')\n",
    "\n",
    "# Df providencia\n",
    "# Crear un nuevo DataFrame con las columnas \"Arenas\" y \"Capacidad\"\n",
    "proveniencia = pd.DataFrame(draft, columns=['organization','organization_type'])  \n",
    "\n",
    "# Eliminar filas duplicadas basadas en la columna \"Arenas\"\n",
    "df_sin_duplicados = proveniencia.drop_duplicates(subset=[\"organization\"])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas \n",
    "proveniencia = df_sin_duplicados\n",
    "\n",
    "# Generar una columna \"ID\" con valores únicos\n",
    "proveniencia[\"ID_proveniencia\"] = range(1, len(proveniencia) + 1)\n",
    "\n",
    "# Unir los DataFrames en función de las columnas \"NombreOrganizacion\" y \"Tipo\"\n",
    "merge = pd.merge(draft, proveniencia, on=[\"organization\", \"organization_type\"], how=\"left\")\n",
    "\n",
    "draft = merge\n",
    "\n",
    "draft = draft.drop(columns=['organization','organization_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV\n",
    "df_common_player_info = pd.read_csv('common_player_info.csv')\n",
    "\n",
    "#DF Players\n",
    "player = df_common_player_info.drop(columns=['display_first_last','display_last_comma_first','display_fi_last','player_slug','last_affiliation','rosterstatus','games_played_current_season_flag','team_name','team_abbreviation','team_code','team_city','playercode','from_year','to_year','dleague_flag','nba_flag','games_played_flag','draft_year','draft_round','draft_number','greatest_75_flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un rango de fechas\n",
    "start_date = '1946-01-01'\n",
    "end_date = '2023-12-31'\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Crear un DataFrame\n",
    "df_date = pd.DataFrame(date_range, columns=['Date'])\n",
    "\n",
    "# Agregar columnas adicionales\n",
    "df_date['Year'] = df_date['Date'].dt.year\n",
    "df_date['Month'] = df_date['Date'].dt.month\n",
    "df_date['Day'] = df_date['Date'].dt.day\n",
    "df_date['Weekday'] = df_date['Date'].dt.weekday\n",
    "df_date['Quarter'] = df_date['Date'].dt.quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame Games y GameStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los archivos CSV\n",
    "df_game = pd.read_csv('game.csv')  \n",
    "df_game_info = pd.read_csv('game_info.csv')  \n",
    "df_game_summary = pd.read_csv('game_summary.csv')  \n",
    "df_line_score = pd.read_csv('line_score.csv')\n",
    "\n",
    "# Unir las tablas\n",
    "df_combine = df_game.merge(df_game_info, on='game_id', how='outer')\n",
    "\n",
    "df_combine_summary = df_combine.merge(df_game_summary, on='game_id', how='outer')\n",
    "\n",
    "df_combine_total = df_combine_summary.merge(df_line_score, on='game_id', how='outer')\n",
    "\n",
    "# Seleccionar las columnas\n",
    "\n",
    "df_game_stats = df_combine_total[['game_id','pts_home_x', 'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home', 'pts_qtr4_home', \n",
    "                                  'pts_qtr1_away', 'pts_qtr2_away', 'pts_qtr3_away', 'pts_qtr4_away', 'pts_away_x', \n",
    "                                  'attendance', 'game_time', 'natl_tv_broadcaster_abbreviation', 'live_period_time_bcast']]\n",
    "\n",
    "\n",
    "df_games = df_combine_total[['game_id', 'game_date_x', 'team_id_home_x', 'wl_home', 'team_id_away_x', 'wl_away', 'season_id', 'season', 'season_type']]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
