{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AUTOMATIZACIÓN DE INGESTA DE DATOS NUEVOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar la librería WATCHDOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Watcher:\n",
    "    # Directorio que se va a observar\n",
    "    DIRECTORY_TO_WATCH = \"C:/Users/Usuario/Desktop/aaa\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Inicialización del observador\n",
    "        self.observer = Observer()\n",
    "\n",
    "    def run(self):\n",
    "        # Creación de un manejador de eventos\n",
    "        event_handler = Handler()\n",
    "        # Configuración del observador para que observe el directorio y subdirectorios\n",
    "        self.observer.schedule(event_handler, self.DIRECTORY_TO_WATCH, recursive=True)\n",
    "        # Inicio del observador\n",
    "        self.observer.start()\n",
    "        try:\n",
    "            # Bucle infinito para mantener el programa en ejecución\n",
    "            while True:\n",
    "                # Pausa de 1 segundo para evitar un uso excesivo de la CPU\n",
    "                time.sleep(1)\n",
    "        except KeyboardInterrupt:\n",
    "            # Detener el observador si se detecta una interrupción del teclado (Ctrl + C)\n",
    "            self.observer.stop()\n",
    "        # Esperar a que el observador termine antes de salir del programa\n",
    "        self.observer.join()\n",
    "\n",
    "class Handler(FileSystemEventHandler):\n",
    "    @staticmethod\n",
    "    def on_modified(event):\n",
    "        # Verificar si el evento corresponde a un directorio\n",
    "        if event.is_directory:\n",
    "            return None\n",
    "        # Verificar si el evento es una modificación de archivo\n",
    "        elif event.event_type == 'modified':\n",
    "            # Aquí puedes poner el código que quieres ejecutar:\n",
    "            \n",
    "            #-------------------------------------- CÓDIGO A EJECUTAR --------------------------------------# \n",
    "            import pyodbc\n",
    "            server = 'localhost\\\\SQLEXPRESS'\n",
    "            database = 'master'\n",
    "            \n",
    "            # Create a connection string\n",
    "            conn_str = (\n",
    "            'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "            'SERVER=' + server + ';'  # replace with your server name\n",
    "            'DATABASE=' + database + ';'  # the database you want to connect to\n",
    "            'Trusted_Connection=yes;'\n",
    "            \n",
    "            # Create a connection\n",
    "            conn = pyodbc.connect(conn_str, autocommit=True) # El autocommint en True permite crear la base desde el código\n",
    "\n",
    "            # Create a cursor\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # Execute the CREATE DATABASE statement\n",
    "            cursor.execute('CREATE DATABASE DAFT01_Grupo1_nba')  # replace with your database name\n",
    "\n",
    "            # Close the cursor and the connection\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            )\n",
    "            \n",
    "            database = 'DAFT01_Grupo1_nba' # Cambiar a la base de datos que ocupemos\n",
    "\n",
    "            # Create a connection string\n",
    "            conn_str = (\n",
    "                'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                'SERVER=' + server + ';'  # replace with your server name\n",
    "                'DATABASE=' + database + ';'  # the database you want to connect to\n",
    "                'Trusted_Connection=yes;'\n",
    "            )\n",
    "\n",
    "            # Create a connection\n",
    "            conn = pyodbc.connect(conn_str, autocommit=True)\n",
    "\n",
    "            # Crear un cursor\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # Crear Proveniencia\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE Proveniencia (\n",
    "                ID_proveniencia INT PRIMARY KEY,\n",
    "                organization_type NVARCHAR(100),\n",
    "                organization NVARCHAR(100),\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "            # Crear State\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE State (\n",
    "                ID_state INT PRIMARY KEY,\n",
    "                state NVARCHAR(100),\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "            # Crear City\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE City (\n",
    "                ID_city INT PRIMARY KEY,\n",
    "                city NVARCHAR(100),\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "            # Crear Location\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE Location (\n",
    "                ID_location INT PRIMARY KEY,\n",
    "                ID_city INT,\n",
    "                ID_state INT,\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "            # Crear Player\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE Player (\n",
    "                ID_player INT PRIMARY KEY,\n",
    "                player_name NVARCHAR(100),\n",
    "                birthdate DATE,\n",
    "                height NVARCHAR(100),\n",
    "                weight INT,\n",
    "                season_exp FLOAT,\n",
    "                jersey NVARCHAR(100),\n",
    "                position NVARCHAR(100),\n",
    "                ID_team INT,\n",
    "                is_active INT,\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "            # Crear teams_History\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE teams_History (\n",
    "                ID_history INT PRIMARY KEY,\n",
    "                ID_team INT,\n",
    "                year_founded INT,\n",
    "                year_active_till INT,\n",
    "                estado INT,\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "            # Crear teams\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE teams (\n",
    "                ID_team INT PRIMARY KEY,\n",
    "                full_name NVARCHAR(100),\n",
    "                abbreviation NVARCHAR(100),\n",
    "                owner NVARCHAR(100),\n",
    "                generalmanager NVARCHAR(100),\n",
    "                headcoach NVARCHAR(100),\n",
    "                ID_location INT,\n",
    "                ID_arena INT,\n",
    "                ID_history INT,\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "            # Crear Arena\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE Arena (\n",
    "                ID_arena INT PRIMARY KEY,\n",
    "                arena NVARCHAR(100),\n",
    "                arenacapacity INT,\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "            # Crear Games\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE Games (\n",
    "                ID_game INT PRIMARY KEY,\n",
    "                game_date DATE,\n",
    "                ID_team INT,\n",
    "                wl_home NVARCHAR(100),\n",
    "                team_id_away INT,\n",
    "                wl_away NVARCHAR(100),\n",
    "                ID_season INT,\n",
    "                ID_location INT,\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "            # Crear season\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE season (\n",
    "                ID_season INT PRIMARY KEY,\n",
    "                season_type NVARCHAR(100),\n",
    "                season INT,\n",
    "            )\n",
    "            ''')\n",
    "\n",
    "            # Crear Draft\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE Draft (\n",
    "                ID_draft INT PRIMARY KEY,\n",
    "                ID_player INT,\n",
    "                player_name NVARCHAR(100),\n",
    "                weight INT,\n",
    "                wingspan FLOAT,\n",
    "                standing_reach FLOAT,\n",
    "                body_fat_pct FLOAT,\n",
    "                standing_vertical_leap FLOAT,\n",
    "                max_vertical_leap FLOAT,\n",
    "                lane_agility_time FLOAT,\n",
    "                modified_lane_agility_time FLOAT,\n",
    "                three_quarter_sprint FLOAT,\n",
    "                bench_press FLOAT,     \n",
    "                round_number INT,\n",
    "                round_pick INT,\n",
    "                overall_pick INT,\n",
    "                ID_team INT,\n",
    "                ID_proveniencia INT, \n",
    "                ID_season INT,     \n",
    "            )\n",
    "            ''')\n",
    "\n",
    "            # Crear Game_stats\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE Game_stats (\n",
    "                ID_game_stats INT PRIMARY KEY,\n",
    "                ID_game INT,\n",
    "                pts_home_x INT,\n",
    "                pts_qtr1_home INT,\n",
    "                pts_qtr2_home INT,\n",
    "                pts_qtr3_home INT,\n",
    "                pts_qtr4_home INT,\n",
    "                pts_qtr1_away INT,\n",
    "                pts_qtr2_away INT,\n",
    "                pts_qtr3_away INT,\n",
    "                pts_qtr4_away INT,\n",
    "                pts_away_x INT,\n",
    "                attendance INT,\n",
    "                game_time NVARCHAR(100),\n",
    "                natl_tv_broadcaster_abbreviation NVARCHAR(100),\n",
    "                live_period_time_bcast NVARCHAR(100),           \n",
    "            )\n",
    "            ''')\n",
    "\n",
    "\n",
    "            # GENERACIÓN DE RELACIONES: \n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE Player\n",
    "            ADD CONSTRAINT FK_Player_teams\n",
    "            FOREIGN KEY(ID_team) REFERENCES teams(ID_team);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE Draft\n",
    "            ADD CONSTRAINT FK_Draft_Player\n",
    "            FOREIGN KEY(ID_player) REFERENCES Player(ID_player);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE Draft\n",
    "            ADD CONSTRAINT FK_Draft_teams\n",
    "            FOREIGN KEY(ID_team) REFERENCES teams(ID_team);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE Draft\n",
    "            ADD CONSTRAINT FK_Draft_Proveniencia\n",
    "            FOREIGN KEY(ID_proveniencia) REFERENCES Proveniencia(ID_proveniencia);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE Draft\n",
    "            ADD CONSTRAINT FK_Draft_season\n",
    "            FOREIGN KEY(ID_season) REFERENCES season(ID_season);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE teams\n",
    "            ADD CONSTRAINT FK_teams_Location\n",
    "            FOREIGN KEY(ID_location) REFERENCES Location(ID_location);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE teams_History\n",
    "            ADD CONSTRAINT FK_teams_History\n",
    "            FOREIGN KEY(ID_team) REFERENCES teams(ID_team);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE teams\n",
    "            ADD CONSTRAINT FK_teams_Arena\n",
    "            FOREIGN KEY(ID_arena) REFERENCES Arena(ID_arena);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE Game_stats\n",
    "            ADD CONSTRAINT FK_Game_stats\n",
    "            FOREIGN KEY(ID_game) REFERENCES Games(ID_game);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE Games\n",
    "            ADD CONSTRAINT FK_Games_season\n",
    "            FOREIGN KEY(ID_season) REFERENCES season(ID_season);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE Games\n",
    "            ADD CONSTRAINT FK_Games_Location\n",
    "            FOREIGN KEY(ID_location) REFERENCES Location(ID_location);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE Location\n",
    "            ADD CONSTRAINT FK_Location_State\n",
    "            FOREIGN KEY(ID_state) REFERENCES State(ID_state);\n",
    "            ''')\n",
    "\n",
    "            cursor.execute('''\n",
    "            ALTER TABLE Location\n",
    "            ADD CONSTRAINT FK_Location_City\n",
    "            FOREIGN KEY(ID_city) REFERENCES City(ID_city);\n",
    "            ''')\n",
    "\n",
    "            # Confirmar los cambios\n",
    "            conn.commit()\n",
    "\n",
    "            # Cerrar la conexión\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            \n",
    "            import pandas as pd\n",
    "            import numpy as np\n",
    "            \n",
    "            # Cargar los CSV a los dfs con las columnas que vamos a ocupar\n",
    "            df_team = pd.read_csv('csv/team.csv', usecols=['id', 'full_name','abbreviation','city', 'state'])\n",
    "            df_team_details = pd.read_csv('csv/team_details.csv', usecols=['team_id','owner', 'generalmanager','headcoach', 'arena', 'arenacapacity'])\n",
    "            df_team_history = pd.read_csv('csv/team_history.csv', usecols=['team_id', 'year_founded', 'year_active_till'])\n",
    "\n",
    "            new_teams_data = {\n",
    "                'team_id': [1610612738, 1610612739, 1610612752, 1610612740, 1610612753],\n",
    "                'owner': ['Wyc Grousbeck, Steve Pagliuca, y otros socios', 'Dan Gilbert', 'James Dolan (Madison Square Garden Sports)', 'Gayle Benson', 'RDV Sports, Inc. (familia DeVos)'],\n",
    "                'generalmanager': ['Brad Stevens', 'Mike Gansey', 'Scott Perry', 'Trajan Langdon', 'Anthony Parker'],\n",
    "                'headcoach': ['Joe Mazzulla', 'J.B. Bickerstaff', 'Tom Thibodeau', 'Willie Green', 'Jamahl Mosley'],\n",
    "                'arena': ['TD Garden', 'Rocket Mortgage FieldHouse', 'Madison Square Garden', 'Smoothie King Center', 'Amway Center'],\n",
    "                'arenacapacity': [19156, 19432, 19812, 16867, 18846]\n",
    "            }\n",
    "\n",
    "            # Crear DataFrame con nuevos datos\n",
    "            df_new_teams = pd.DataFrame(new_teams_data)\n",
    "\n",
    "            # Concatenar DataFrames\n",
    "            df_team_details = pd.concat([df_team_details, df_new_teams], ignore_index=True)\n",
    "\n",
    "            # Renombrar la columna id a team_id\n",
    "            df_team = df_team.rename(columns={'id': 'team_id'})\n",
    "\n",
    "            # Fusionar las tablas df_team y df_team_details\n",
    "            df_fusionado = pd.merge(df_team, df_team_details, on='team_id', how='outer')\n",
    "\n",
    "            # Fusionar la tabla resultante anterior con df_team_history\n",
    "            df_fusionado2 = pd.merge(df_fusionado, df_team_history, on='team_id', how='outer')\n",
    "\n",
    "            teams = df_fusionado2.rename(columns={'team_id': 'id'})\n",
    "\n",
    "            # Encontrar el valor máximo de la columna 'year_active_till'\n",
    "            max_year_active_till = teams['year_active_till'].max()\n",
    "\n",
    "            # Agregar la columna 'estado' basada en la condición\n",
    "            teams['estado'] = np.where(teams['year_active_till'] < max_year_active_till, 0, 1)\n",
    "\n",
    "            # Agregado de la tabla location al dataframe\n",
    "            # Crear un nuevo DataFrame con las columnas \"state\" y \"city\"\n",
    "            location = pd.DataFrame(teams, columns=['state','city'])\n",
    "\n",
    "            # Eliminar filas duplicadas basadas en la columna \"city\"\n",
    "            df_location_sin_duplicados = location.drop_duplicates(subset=['city'])\n",
    "\n",
    "            # Crear un nuevo DataFrame con las columnas\n",
    "            location = df_location_sin_duplicados\n",
    "\n",
    "            # Generar una columna \"ID\" con valores únicos\n",
    "            location['ID_location'] = range(1, len(location) + 1) \n",
    "\n",
    "            # Unir los DataFrames en función de las columnas \"city\" y \"state\"\n",
    "            merge_location = pd.merge(teams, location, on=['city','state'], how='left')\n",
    "\n",
    "            teams = merge_location\n",
    "\n",
    "            teams = teams.drop(columns=['city','state'])\n",
    "\n",
    "            ##Agregado de la tabla arena al dataframe\n",
    "            # Crear un nuevo DataFrame con las columnas \"arena\" y \"arenacapacity\"\n",
    "            arena = pd.DataFrame(teams, columns=['arena','arenacapacity'])\n",
    "\n",
    "            # Eliminar filas duplicadas basadas en la columna \"city\"\n",
    "            df_arena_sin_duplicados = arena.drop_duplicates(subset=['arena'])\n",
    "\n",
    "            # Crear un nuevo DataFrame con las columnas\n",
    "            arena = df_arena_sin_duplicados\n",
    "\n",
    "            # Generar una columna \"ID\" con valores únicos\n",
    "            arena['ID_arena'] = range(1, len(arena) + 1) \n",
    "\n",
    "            # Unir los DataFrames en función de las columnas \"city\" y \"state\"\n",
    "            merge_arena = pd.merge(teams, arena, on=['arenacapacity','arena'], how='left')\n",
    "\n",
    "            teams = merge_arena\n",
    "\n",
    "            teams.rename(columns={\"id\": \"ID_team\"}, inplace=True)\n",
    "\n",
    "            teams = teams.drop(columns=['arenacapacity','arena','year_founded','year_active_till','estado'])\n",
    "\n",
    "            teams_History = df_team_history.rename(columns={'team_id': 'ID_team'})\n",
    "\n",
    "            # Generar una columna \"ID\" con valores únicos\n",
    "            teams_History['ID_history'] = range(1, len(teams_History) + 1)\n",
    "\n",
    "            teams = teams.drop_duplicates(subset='ID_team')\n",
    "\n",
    "            teams.fillna('Darko Rajaković', inplace=True)\n",
    "            \n",
    "            # Df city\n",
    "            city_unique = df_team['city'].unique()  # Obtiene los valores únicos de la columna 'city'\n",
    "            city = pd.DataFrame(city_unique, columns=['city'])  # Crea un DataFrame con los valores únicos\n",
    "\n",
    "            city['ID_city'] = range(1, len(city) + 1)  #Creo el indice\n",
    "\n",
    "            # Df state\n",
    "            state_unique = df_team['state'].unique()  # Obtiene los valores únicos de la columna 'state'\n",
    "            state = pd.DataFrame(state_unique, columns=['state'])  # Crea un DataFrame con los valores únicos\n",
    "\n",
    "            state['ID_state'] = range(1, len(state) + 1)  #Creo el indice\n",
    "\n",
    "            #Megere\n",
    "            # Unir los DataFrames en función de las columnas \"city\" y \"state\"\n",
    "            merge_city = pd.merge(city, location, on=['city'], how='left')\n",
    "            merge_total = pd.merge(state, merge_city, on=['state'], how='left')\n",
    "\n",
    "            merge_total = merge_total.drop(columns=['state','city'])\n",
    "\n",
    "            #Borro columnas de location\n",
    "            location = merge_total\n",
    "            \n",
    "            # Leer los archivos CSV\n",
    "            df_draft_combine_stats = pd.read_csv('csv/draft_combine_stats.csv')\n",
    "            df_draft_history = pd.read_csv('csv/draft_history.csv')\n",
    "\n",
    "            # Seleccion de las columnas a utilizar\n",
    "            columnas_draft_combine_stats  = ['player_id','weight','wingspan','standing_reach','body_fat_pct','standing_vertical_leap','max_vertical_leap','lane_agility_time','modified_lane_agility_time','three_quarter_sprint','bench_press']\n",
    "            df_draft_combine_stats_reducido = df_draft_combine_stats.loc[:,columnas_draft_combine_stats]\n",
    "\n",
    "            columnas_draft_history  = ['person_id','season','player_name','round_number','round_pick','overall_pick','team_id','organization','organization_type']\n",
    "            df_draft_history_reducido = df_draft_history.loc[:,columnas_draft_history]\n",
    "\n",
    "            df_draft_history_reducido.rename(columns={\"person_id\": \"player_id\"}, inplace=True)\n",
    "\n",
    "            # DataFrame Draft\n",
    "            draft = pd.merge(df_draft_combine_stats_reducido, df_draft_history_reducido, on='player_id', how='outer')\n",
    "\n",
    "            # Df proveniencia\n",
    "            # Crear un nuevo DataFrame con las columnas \"organization\" y \"organization_type\"\n",
    "            proveniencia = pd.DataFrame(draft, columns=['organization','organization_type'])  \n",
    "\n",
    "            # Eliminar filas duplicadas basadas en la columna \"organization\"\n",
    "            df_sin_duplicados = proveniencia.drop_duplicates(subset=[\"organization\"])\n",
    "\n",
    "            # Crear un nuevo DataFrame con las columnas \n",
    "            proveniencia = df_sin_duplicados\n",
    "\n",
    "            # Generar una columna \"ID\" con valores únicos\n",
    "            proveniencia[\"ID_proveniencia\"] = range(1, len(proveniencia) + 1)\n",
    "\n",
    "            # Unir los DataFrames en función de las columnas \"organization\" y \"organization_type\"\n",
    "            merge = pd.merge(draft, proveniencia, on=[\"organization\", \"organization_type\"], how=\"left\")\n",
    "\n",
    "            draft = merge\n",
    "\n",
    "            draft = draft.drop(columns=['organization','organization_type'])\n",
    "\n",
    "            draft = draft.rename(columns={'player_id':'ID_player', 'team_id':'ID_team'})\n",
    "\n",
    "            draft = draft[draft['ID_team']>=1610612737]\n",
    "            \n",
    "            # Leer el archivo CSV\n",
    "            df_common_player_info = pd.read_csv('csv/common_player_info.csv')\n",
    "            df_inactive_players = pd.read_csv('csv/inactive_players.csv')\n",
    "            df_player = pd.read_csv('csv/player.csv')\n",
    "\n",
    "            #DF Players\n",
    "            player = df_common_player_info.drop(columns=['display_first_last','school','country','display_last_comma_first','display_fi_last','player_slug','last_affiliation','rosterstatus','games_played_current_season_flag','team_name','team_abbreviation','team_code','team_city','playercode','from_year','to_year','dleague_flag','nba_flag','games_played_flag','draft_year','draft_round','draft_number','greatest_75_flag'])\n",
    "            # Renombrar la columna id a person_id\n",
    "            df_player = df_player.rename(columns={'id': 'person_id'})\n",
    "\n",
    "            # Fusionar las tablas df_player y player\n",
    "            player = pd.merge(player, df_player, on='person_id', how='inner')\n",
    "            player = player.drop(columns=['last_name_y','first_name_y','full_name'])\n",
    "\n",
    "            # Renombrar la columna id a ID_player\n",
    "            player = player.rename(columns={'person_id': 'ID_player', 'first_name_x':'first_name', 'last_name_x':'last_name', 'team_id':'ID_team'})\n",
    "\n",
    "            player = player[player['ID_team']>=1610612737]\n",
    "            \n",
    "            # Cargar los archivos CSV\n",
    "            df_game = pd.read_csv('csv/game.csv')  \n",
    "            df_game_info = pd.read_csv('csv/game_info.csv')  \n",
    "            df_game_summary = pd.read_csv('csv/game_summary.csv')  \n",
    "            df_line_score = pd.read_csv('csv/line_score.csv')\n",
    "\n",
    "            # Unir las tablas\n",
    "            df_combine = df_game.merge(df_game_info, on='game_id', how='inner')\n",
    "\n",
    "            df_combine_summary = df_combine.merge(df_game_summary, on='game_id', how='inner')\n",
    "\n",
    "            df_combine_total = df_combine_summary.merge(df_line_score, on='game_id', how='inner')\n",
    "\n",
    "            # Seleccionar las columnas\n",
    "\n",
    "            game_stats = df_combine_total[['game_id','pts_home_x', 'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home', 'pts_qtr4_home', \n",
    "                                            'pts_qtr1_away', 'pts_qtr2_away', 'pts_qtr3_away', 'pts_qtr4_away', 'pts_away_x', \n",
    "                                            'attendance', 'game_time', 'natl_tv_broadcaster_abbreviation', 'live_period_time_bcast']]\n",
    "\n",
    "            game_stats['ID_game_stats'] = range(1, len(game_stats) + 1)  # Creación del id\n",
    "\n",
    "\n",
    "            df_games = df_combine_total[['game_id', 'game_date_x', 'team_id_home_x', 'wl_home', 'team_id_away_x', 'wl_away', 'season_id', 'season', 'season_type']]\n",
    "\n",
    "            # Renombrar la columna team_id_home a ID_team en df_games\n",
    "            df_games = df_games.rename(columns={'team_id_home_x': 'ID_team'})\n",
    "\n",
    "            games = pd.merge(df_games, teams[['ID_team', 'ID_location']], on='ID_team', how='outer')\n",
    "\n",
    "\n",
    "            # Renombrar la columna game_id a ID_game\n",
    "            games = games.rename(columns={'game_id': 'ID_game', 'game_date_x': 'game_date', 'team_id_away_x': 'team_id_away'})\n",
    "\n",
    "\n",
    "            # Creación de tabla de Season \n",
    "            df_season = df_combine_total[['season_id', 'season', 'season_type']]\n",
    "            season = df_season.drop_duplicates(subset=['season_id'])\n",
    "            season = season.rename(columns={'season_id': 'ID_season'})\n",
    "            season = season.drop_duplicates(subset='ID_season')\n",
    "\n",
    "            games = games.rename(columns={'season_id': 'ID_season'})\n",
    "            games = games.drop(columns=['season','season_type'])\n",
    "            games = games.drop_duplicates(subset='ID_game')\n",
    "\n",
    "            game_stats = game_stats.rename(columns={'game_id': 'ID_game'})\n",
    "\n",
    "            # ID_season en tabla de Draft\n",
    "            draft = pd.merge(draft, season[['ID_season', 'season']], on='season', how='inner')\n",
    "            draft_d = draft.drop(columns=['season'])\n",
    "            draft = draft_d\n",
    "\n",
    "            draft['ID_draft'] = range(1, len(draft) + 1)  # Creación del id\n",
    "\n",
    "            games = games[games['ID_team']>=1610612737]\n",
    "\n",
    "\n",
    "            # Arreglo de errores\n",
    "\n",
    "            prueba = pd.merge(player,draft[['ID_player','player_name']],on='ID_player',how='outer')\n",
    "            prueba = prueba.drop_duplicates('ID_player')\n",
    "            prueba_2 = prueba.dropna(subset=['player_name'])\n",
    "            player = prueba_2.drop(columns=['first_name','last_name'])\n",
    "\n",
    "            game_stats = game_stats.drop_duplicates(subset='ID_game')\n",
    "\n",
    "            game_stats = pd.merge(game_stats, games['ID_game'], on='ID_game', how='inner')\n",
    "            \n",
    "            from sqlalchemy import create_engine\n",
    "\n",
    "            # Parámetros de la conexión\n",
    "            server = 'localhost\\\\SQLEXPRESS'  # Reemplaza con el nombre de tu servidor\n",
    "            database = 'DAFT01_Grupo1_nba'  # Reemplaza con el nombre de tu base de datos\n",
    "\n",
    "            # Crear la cadena de conexión utilizando la autenticación de Windows\n",
    "            connection_string = f'mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes'\n",
    "\n",
    "            # Crear el motor de conexión\n",
    "            engine = create_engine(connection_string)\n",
    "\n",
    "            # Mandar los datos a la tabla ya creada en SQL Server\n",
    "            season.to_sql('season', engine, if_exists='append', index=False)\n",
    "            state.to_sql('State', engine, if_exists='append', index=False)\n",
    "            city.to_sql('City', engine, if_exists='append', index=False)\n",
    "            arena.to_sql('Arena', engine, if_exists='append', index=False)\n",
    "            location.to_sql('Location', engine, if_exists='append', index=False)\n",
    "            proveniencia.to_sql('Proveniencia', engine, if_exists='append', index=False)\n",
    "            teams.to_sql('teams', engine, if_exists='append', index=False)\n",
    "            teams_History.to_sql('teams_History', engine, if_exists='append', index=False)\n",
    "            games.to_sql('Games', engine, if_exists='append', index=False)\n",
    "            game_stats.to_sql('Game_stats', engine, if_exists='append', index=False)\n",
    "            player.to_sql('Player', engine, if_exists='append', index=False)\n",
    "            draft.to_sql('Draft', engine, if_exists='append', index=False)\n",
    "\n",
    "            #-------------------------------------- FIN DEL CÓDIGO --------------------------------------# \n",
    "\n",
    "            print(f'Archivo modificado: {event.src_path}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Crear una instancia de la clase Watcher y ejecutar el método run()\n",
    "    w = Watcher()\n",
    "    w.run()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
